{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def count_words_fast(text): \n",
    "    text = text.lower() \n",
    "    skips = [\".\", \",\", \";\", \":\", \"'\", '\"', \"\\n\", \"!\", \"?\", \"(\", \")\"] \n",
    "    for ch in skips: \n",
    "        text = text.replace(ch, \"\") \n",
    "    word_counts = Counter(text.split(\" \")) \n",
    "    return word_counts\n",
    "\n",
    "def word_stats(word_counts): \n",
    "    num_unique = len(word_counts) \n",
    "    counts = word_counts.values() \n",
    "    return (num_unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2, dict_values([2, 1]))"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "hamlets = pd.read_csv(\n",
    "    \"https://courses.edx.org/asset-v1:HarvardX+PH526x+2T2019+type@asset+block@hamlets.csv\", index_col=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'book_titles' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-162b571a82ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtitle_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbook_titles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mauthor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbook_titles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbook_titles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'book_titles' is not defined"
     ]
    }
   ],
   "source": [
    "book_dir = \"Books\"\n",
    "title_num = 1\n",
    "\n",
    "for language in book_titles:\n",
    "    for author in book_titles[language]:\n",
    "        for title in book_titles[language][author]:\n",
    "            if title == \"Hamlet\":\n",
    "                inputfile = data_filepath+\"Books/\"+language+\"/\"+author+\"/\"+title+\".txt\"\n",
    "                text = read_book(inputfile)\n",
    "                distribution = word_count_distribution(text) \n",
    "                hamlets.loc[title_num] = language, distribution\n",
    "                title_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "word  \\\n1  (﻿hamlet, prinz, von, dännemarkwilliam, shakes...   \n2  (the, tragedie, of, hamletactus, primus, scoen...   \n3  (﻿hamletdrama, em, cinco, actoswilliam, shakes...   \n\n                                               count  \n1  (1, 17, 262, 1, 1, 2, 2, 1, 1, 56, 374, 2, 1, ...  \n2  (855, 2, 550, 1, 1, 1, 1, 8, 601, 2, 19, 1, 18...  \n3  (1, 200, 5, 1, 1, 1, 1, 1, 1, 707, 1, 665, 20,...  \n"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def count_words_fast(text):\n",
    "    text = text.lower()\n",
    "    skips = [\".\", \",\", \";\", \":\", \"'\", '\"', \"\\n\", \"!\", \"?\", \"(\", \")\"]\n",
    "    for ch in skips:\n",
    "        text = text.replace(ch, \"\")\n",
    "    word_counts = Counter(text.split(\" \"))\n",
    "    return word_counts\n",
    "\n",
    "\n",
    "def word_stats(text):\n",
    "    word_counts = count_words_fast(text)\n",
    "    num_unique = len(word_counts)\n",
    "    counts = word_counts.values()\n",
    "    return (num_unique, counts)\n",
    "\n",
    "\n",
    "def read_book(filename):\n",
    "    \"\"\"\n",
    "    We read file from each folder based on theor catagory and return file as Text \n",
    "    \"\"\"\n",
    "    with open(filename, 'r', encoding='utf8') as currentfile:\n",
    "        text = currentfile.read()\n",
    "        text = text.replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n",
    "        sp_char = [\",\", \".\", \"?\", \"!\", '\"', \"'\", \";\", \":\", \"!\"]\n",
    "        for ch in sp_char:\n",
    "            text = text.replace(ch, \"\")\n",
    "    return text\n",
    "\n",
    "\n",
    "hamlets = pd.read_csv(\n",
    "    \"asset-v1 HarvardX+PH526x+2T2019+type@asset+block@hamlets.csv\", index_col=0)\n",
    "# print(hamlets)\n",
    "\n",
    "language, text = hamlets.iloc[0]\n",
    "\n",
    "data = pd.DataFrame(columns=(\"word\", \"count\"))\n",
    "file_number = 1\n",
    "\n",
    "directory = \"/home/divyesh/PHD2020/python_practice/Python_for_research/Project_Gutenberg/Books_Language\"\n",
    "os.listdir(directory)\n",
    "for language in os.listdir(directory):\n",
    "    for author in os.listdir(directory + \"/\" + language):\n",
    "        for title in os.listdir(directory + \"/\" + language + \"/\" + author):\n",
    "            if title == \"Hamlet.txt\":\n",
    "                input_file = directory + \"/\" + language + \"/\" + author + \"/\" + title\n",
    "                text = read_book(input_file)\n",
    "                (num_unique_words, length_file) = word_stats(text)\n",
    "                #stats.loc[file_number] = language, author, title, num_unique_words, length_file\n",
    "                counted_text = count_words_fast(text)\n",
    "                # print(counted_text)\n",
    "                words = counted_text.keys()\n",
    "                data.loc[file_number] = words, counted_text.values()\n",
    "                file_number += 1\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitanaconda3virtualenv4f623ec99707439da8cb674933a4868c",
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}